---
layout: archive
title: "Physical Intelligence and Robotics"
permalink: /research_robotics/
author_profile: true
redirect_from:
  - /robotics
---

{% include base_path %}

This project develops advanced Vision-Language-Action (VLA) models for physical intelligence on our Mobile ALOHA platform. By integrating multimodal perception, language understanding, and adaptive control, we aim to enable autonomous and intelligent real-world task execution.

<img width="124" height="195" alt="image" src="https://github.com/user-attachments/assets/6e8631c2-e92f-4589-9430-d61ae6572432" />
